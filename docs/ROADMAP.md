# FlowQ Roadmap

> Your local AI workspace, in flow.

This document outlines the development roadmap for FlowQ. Features are organized by milestone versions, with status indicators showing current progress.

**Legend:** âœ… Complete | ğŸš§ In Progress | ğŸ“‹ Planned

---

## v0.1 â€” Foundation (Current)

The initial release establishes core functionality.

| Feature | Status | Description |
|---------|--------|-------------|
| Chat Mode | âœ… | Direct conversation with AI models |
| Agent Mode | âœ… | Tool-powered execution with Claude Agent SDK |
| Session Management | âœ… | Create, rename, delete, persist sessions |
| Multi-Provider | âœ… | Anthropic, AWS Bedrock, OpenAI support |
| Workspace Selection | âœ… | Folder-scoped sessions |
| MCP Configuration | âœ… | UI for managing MCP servers |
| Skills Configuration | âœ… | Custom slash commands setup |
| Theme Support | âœ… | Light / Dark / System themes |
| Multimodal Input | âœ… | Text + image messages |
| Markdown Rendering | âœ… | Code highlighting, Mermaid, KaTeX |

---

## v0.2 â€” Core Completion

Polish existing features and complete partial implementations.

| Feature | Status | Description |
|---------|--------|-------------|
| Slash Commands | ğŸš§ | Execute `/settings`, `/history`, `/clear` |
| Custom Skills Execution | ğŸ“‹ | Run user-defined skill prompts |
| Permission Backend | ğŸ“‹ | Approve/deny tool execution requests |
| Model Mentions | ğŸ“‹ | Route messages via `@claude`, `@gpt` syntax |

> **Note:** MCP servers are managed by Claude Code CLI in Agent mode. FlowQ provides configuration UI (`~/.claude.json`), while the CLI handles server lifecycle and tool discovery.

### Slash Commands (`/`) â€” Implementation Suggestions

**Built-in Commands:**

| Command | Action | Notes |
|---------|--------|-------|
| `/settings` | Open settings panel | Optional: `/settings providers` to open specific tab |
| `/clear` | Clear current session messages | Keep session metadata, only clear chat history |
| `/history` | Show session history panel | Jump to ChatList or open search |
| `/new` | Create new session | Same as Cmd+N |
| `/help` | Show available commands | Display command palette with descriptions |
| `/model <name>` | Switch model | e.g., `/model claude-3-opus` |
| `/mode <chat\|agent>` | Switch between Chat/Agent mode | Quick mode toggle |
| `/export` | Export current session | Trigger export dialog |

**Custom Skills Execution:**

Skills from `~/.claude/skills/` should be invokable as `/skill-name`. For example:
- `/commit` â†’ Load `~/.claude/skills/commit/SKILL.md` and execute
- `/review-pr` â†’ Load `~/.claude/skills/review-pr/SKILL.md` and execute

**Implementation Approach:**

1. **Command Registry** â€” Central registry mapping command names to handlers
2. **Autocomplete** â€” Show matching commands as user types `/`
3. **Parameter Parsing** â€” Support commands with arguments: `/model claude-3-opus`
4. **Skill Loading** â€” When command matches a skill name, inject SKILL.md into system prompt and send the user's message

### Mentions (`@`) â€” Implementation Suggestions

**Built-in Mention Types:**

| Mention | Description | Example |
|---------|-------------|---------|
| `@claude` | Use Anthropic Claude | Route to configured Anthropic API |
| `@bedrock` | Use AWS Bedrock Claude | Route to configured Bedrock endpoint |
| `@gpt` | Use OpenAI GPT | Route to configured OpenAI API |
| `@file:path` | Include file content | `@file:src/main.rs` injects file |
| `@folder:path` | Include folder structure | `@folder:src/` lists directory tree |
| `@url:link` | Fetch and include URL content | `@url:https://...` fetches page |
| `@skill:name` | Invoke skill context | `@skill:commit` loads skill prompt |

**Model Routing Architecture:**

```
User Input: "@claude Explain this code @file:main.rs"
                â†“
         Parse Mentions
                â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Model: claude         â”‚
    â”‚ Files: [main.rs]      â”‚
    â”‚ Message: "Explain..." â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â†“
      Route to Anthropic API
```

**Multi-Model Scenarios:**

1. **Single mention** â€” Route entire message to that model
2. **No mention** â€” Use session's default model
3. **Mixed mentions** â€” Primary model processes, others as context
4. **Comparison mode** â€” `@claude vs @gpt: Which approach is better?` â†’ Send to both, show side-by-side

**Implementation Approach:**

1. **Mention Parser** â€” Regex-based extraction: `@(\w+)(?::([^\s]+))?`
2. **Type Detection** â€” Determine if mention is model, file, or skill
3. **Context Injection** â€” Files/skills become part of message context
4. **Router** â€” Based on detected model, select API endpoint
5. **Fallback** â€” If mentioned model not configured, show warning

**UI/UX Considerations:**

- **Autocomplete popup** â€” Show suggestions after `@` keystroke
- **Syntax highlighting** â€” Color mentions differently in input
- **Preview badges** â€” Show resolved mentions as chips/badges
- **File picker** â€” `@file:` triggers file browser
- **Validation** â€” Check file exists, model configured before send

---

## v0.3 â€” Flow Enhancement

Reduce friction and improve daily workflow.

| Feature | Status | Description |
|---------|--------|-------------|
| Keyboard Shortcuts | ğŸ“‹ | `Cmd+N`, `Cmd+K`, `Cmd+/`, `Cmd+Enter` |
| Session Search | ğŸ“‹ | Full-text search across all sessions |
| Quick Switcher | ğŸ“‹ | `Cmd+P` to jump between sessions |
| Context Indicators | ğŸ“‹ | Real-time token usage display |
| Session Pinning | ğŸ“‹ | Pin important sessions to top |

---

## v1.0 â€” Data Portability

Complete data ownership and portability features.

| Feature | Status | Description |
|---------|--------|-------------|
| Export to Markdown | ğŸ“‹ | Download session as `.md` file |
| Export to JSON | ğŸ“‹ | Full session data export |
| Import Sessions | ğŸ“‹ | Import from ChatGPT, Claude.ai exports |
| Local Backup | ğŸ“‹ | Scheduled workspace backups |

---

## Future Considerations

These features are under consideration for post-1.0 releases:

- **Multi-Agent Workflows** â€” Chain agents for complex tasks
- **Local Model Support** â€” Ollama, LM Studio integration
- **Plugin System** â€” User-installable skill extensions
- **Voice Input** â€” Speech-to-text for hands-free operation

---

## Architecture

FlowQ offers two distinct modes:

| Mode | Backend | Tools | MCP | Use Case |
|------|---------|-------|-----|----------|
| **Chat** | Direct API (Anthropic/Bedrock/OpenAI) | âŒ | âŒ | Fast, lightweight conversations |
| **Agent** | Claude Agent SDK â†’ Claude Code CLI | âœ… | âœ… | Tool execution, file operations |

MCP servers configured in FlowQ are stored in `~/.claude.json` and automatically loaded by Claude Code CLI when using Agent mode.

---

## Design Principles

FlowQ development follows these principles:

1. **Local First** â€” Your data stays on your machine
2. **Privacy by Design** â€” No telemetry, no cloud sync
3. **Minimal Friction** â€” Every interaction should feel instant
4. **Focused Experience** â€” One window, one flow

---

## Contributing

We welcome contributions! Here's how to help:

- **Bug Reports** â€” Open an issue with reproduction steps
- **Feature Requests** â€” Discuss in GitHub Discussions first
- **Pull Requests** â€” Fork, branch, and submit PRs against `main`

See the [README](../README.md) for development setup instructions.

---

*Last updated: February 2025*
